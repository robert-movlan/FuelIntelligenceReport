# ğŸ“Š Fuel Intelligence Report â€” GitHub Portfolio Documentation

## ğŸ” Project Overview

This project showcases a full end-to-end data integration solution for a fictional fuel logistics company. The architecture integrates:

* Azure Data Lake Storage Gen2
* Azure Databricks (for processing & transformation)
* Azure Synapse Analytics (for querying and automation)
* Azure Data Factory (for orchestration)

Future phases will include:

* Snowflake integration
* Power Apps for executive dashboards
* Power Automate for alerts
* Canva/Power BI visuals for stakeholders

---

## âœ… Current Status (Phase 1 Completed)

### ğŸ”¸ Data Ingestion:

* âœ… 4 CSV files uploaded to Azure Data Lake under container `fueldata`

  * `clients.csv`
  * `drivers.csv`
  * `fuels.csv`
  * `pump_loads.csv`

### ğŸ”¸ Databricks Processing:

* âœ… Created cluster: `Movlan Aliyevâ€™s Cluster`
* âœ… Notebook `1_ingest_to_datalake.ipynb` performs the following:

  * Joins 4 datasets
  * Cleans and prepares the final data
  * Writes to: `/fueldata/final/fuel_report.parquet`
  * Generates 3 curated parquet files:

    * `/curated/top_drivers.parquet`
    * `/curated/fuel_cost_per_client.parquet`
    * `/curated/fuel_type_usage.parquet`

### ğŸ”¸ Weekly Automation:

* âœ… Created Databricks Job to run notebook
* âœ… Triggered via Azure Synapse Pipeline with Web Activity using REST API
* âœ… Scheduled weekly recurrence trigger using Synapse

### ğŸ”¸ Validation:

* âœ… Successfully queried `fuel_report.parquet` in Synapse using `OPENROWSET`
* âœ… Created 4 SQL scripts:

  * `validate_parquet.sql`
  * `top_drivers.sql`
  * `fuel_cost_per_client.sql`
  * `fuel_type_usage.sql`
* âœ… Screenshots saved for each pipeline, job, and notebook run

---

## âš ï¸ Obstacles Faced & How They Were Resolved

| Issue                                                       | Solution                                                                                               |
| ----------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| Databricks runtime version 15.4 not compatible with Synapse | Changed to Runtime 13.3 LTS                                                                            |
| Spark job failing with 9512 error                           | Manually created Databricks Job and triggered via Synapse Web activity instead of direct notebook link |
| Could not locate `fuel_report.parquet`                      | Found it was in `/fueldata/final/` not `/fueldata/`                                                    |
| Encoding errors for VARCHAR fields                          | Will handle using UTF-8 collation hint in downstream SQL queries                                       |
| Storage credential issues                                   | Fixed by registering App in Azure AD and assigning Storage Blob Data Contributor role                  |

---

## ğŸ“ Folder Structure

```
/Fuel_Intelligence_Report
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clients.csv
â”‚   â”œâ”€â”€ drivers.csv
â”‚   â”œâ”€â”€ fuels.csv
â”‚   â””â”€â”€ pump_loads.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 1_ingest_to_datalake.ipynb
â”‚
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ Refresh_FuelReport_Weekly_support_live/ (exported Synapse pipeline)
â”‚
â”œâ”€â”€ queries/
â”‚   â”œâ”€â”€ validate_parquet.sql
â”‚   â”œâ”€â”€ top_drivers.sql
â”‚   â”œâ”€â”€ fuel_cost_per_client.sql
â”‚   â””â”€â”€ fuel_type_usage.sql
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ upload_to_datalake.png
â”‚   â”œâ”€â”€ notebook_execution.png
â”‚   â””â”€â”€ job_trigger_synapse.png
â”‚
â”œâ”€â”€ readme_docs/
â”‚   â””â”€â”€ Technical_Diary.md 
â”‚
â””â”€â”€ README.md (this file)
```

---

## ğŸ”— Next Steps

* [ ] Create curated Synapse views with aggregations
* [ ] Load `fuel_report.parquet` into Snowflake
* [ ] Build Power Apps for CEO
* [ ] Automate reporting with Power Automate + Canva

---

## ğŸ‘¨â€ğŸ’» Author

**Movlan Aliyev** â€” \[[robert.movlan@outlook.com](mailto:robert.movlan@outlook.com)]
GitHub Portfolio: \[Coming Soon]

---

ğŸ‘‰ For full technical documentation, visit: [`readme_docs/Technical_Diary.md`](./readme_docs/Technical_Diary.md)
